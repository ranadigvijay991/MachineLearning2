{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:35.836583Z",
     "iopub.status.busy": "2021-11-19T09:41:35.835978Z",
     "iopub.status.idle": "2021-11-19T09:41:40.884012Z",
     "shell.execute_reply": "2021-11-19T09:41:40.883272Z",
     "shell.execute_reply.started": "2021-11-19T09:41:35.836483Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3  environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:40.885889Z",
     "iopub.status.busy": "2021-11-19T09:41:40.885632Z",
     "iopub.status.idle": "2021-11-19T09:41:42.170390Z",
     "shell.execute_reply": "2021-11-19T09:41:42.169591Z",
     "shell.execute_reply.started": "2021-11-19T09:41:40.885854Z"
    }
   },
   "outputs": [],
   "source": [
    "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.171901Z",
     "iopub.status.busy": "2021-11-19T09:41:42.171641Z",
     "iopub.status.idle": "2021-11-19T09:41:42.201460Z",
     "shell.execute_reply": "2021-11-19T09:41:42.200750Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.171868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.203999Z",
     "iopub.status.busy": "2021-11-19T09:41:42.203586Z",
     "iopub.status.idle": "2021-11-19T09:41:42.243691Z",
     "shell.execute_reply": "2021-11-19T09:41:42.242995Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.203959Z"
    }
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['source']=='indic2012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.245988Z",
     "iopub.status.busy": "2021-11-19T09:41:42.245577Z",
     "iopub.status.idle": "2021-11-19T09:41:42.261446Z",
     "shell.execute_reply": "2021-11-19T09:41:42.260796Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.245952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>In this lies the circumstances of people befor...</td>\n",
       "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>“”Global Warming“” refer to warming caused in ...</td>\n",
       "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Category: Religious Text</td>\n",
       "      <td>श्रेणी:धर्मग्रन्थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This period summarily is pepped up with devotion.</td>\n",
       "      <td>यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>And now at present the naturecure, Ayurvedic a...</td>\n",
       "      <td>हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Parliament time frame is 5 years and this will...</td>\n",
       "      <td>लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय स...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Extreme weather due to increased mortality; di...</td>\n",
       "      <td>बढ़ती हुई मौतों displacements और आर्थिक नुकसान...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Islam is the world's second-largest religion, ...</td>\n",
       "      <td>इस्लाम धर्म (الإسلام) ईसाई धर्म के बाद अनुयाइ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Maine</td>\n",
       "      <td>मेन</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>IN farsi philosophy firdaus garden is presente...</td>\n",
       "      <td>फारसी रहस्यवाद में मुगल कालीन इस्लामी पाठ्य मे...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>But after his demise, his bother Sardar Vallab...</td>\n",
       "      <td>मगर उनके निधन के पश्चात उनके भाई सरदार वल्लभ भ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This position is similar to armchair. In this ...</td>\n",
       "      <td>-झूला यह हत्थाकुर्सी से मिलती जुलती पोजीशन है ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>category:information technology</td>\n",
       "      <td>श्रेणी:सूचना प्रौद्योगिकी</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Aryans did not make any statues or temples for...</td>\n",
       "      <td>आर्य देवताओं की कोई मूर्ति या मन्दिर नहीं बनात...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>It has three small domes and has been construc...</td>\n",
       "      <td>यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संग...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.Sarojini Naidu with Mahatma Gandhi</td>\n",
       "      <td>महात्मा गांधी के साथ सरोजिनी नायडू</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>External links</td>\n",
       "      <td>बाहरी कड़ियाँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>Buddha and danceroom (1958)</td>\n",
       "      <td>बुद्ध और नाचघर (1958)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "2   indic2012  This percentage is even greater than the perce...   \n",
       "4   indic2012  .The ending portion of these Vedas is called U...   \n",
       "6   indic2012  In this lies the circumstances of people befor...   \n",
       "8   indic2012  “”Global Warming“” refer to warming caused in ...   \n",
       "11  indic2012                           Category: Religious Text   \n",
       "12  indic2012  This period summarily is pepped up with devotion.   \n",
       "16  indic2012  And now at present the naturecure, Ayurvedic a...   \n",
       "17  indic2012  Parliament time frame is 5 years and this will...   \n",
       "19  indic2012  Extreme weather due to increased mortality; di...   \n",
       "22  indic2012  Islam is the world's second-largest religion, ...   \n",
       "33  indic2012                                              Maine   \n",
       "34  indic2012  IN farsi philosophy firdaus garden is presente...   \n",
       "40  indic2012  But after his demise, his bother Sardar Vallab...   \n",
       "48  indic2012  This position is similar to armchair. In this ...   \n",
       "50  indic2012                    category:information technology   \n",
       "57  indic2012  Aryans did not make any statues or temples for...   \n",
       "58  indic2012  It has three small domes and has been construc...   \n",
       "59  indic2012                .Sarojini Naidu with Mahatma Gandhi   \n",
       "61  indic2012                                     External links   \n",
       "69  indic2012                        Buddha and danceroom (1958)   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "2    यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "4         इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
       "6    इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।  \n",
       "8   ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...  \n",
       "11                                  श्रेणी:धर्मग्रन्थ  \n",
       "12      यह काल समग्रतः भक्ति भावना से ओतप्रोत काल है।  \n",
       "16  हाल में नेपाल के हस्पताल सामन्यतया आयुर्वेद, प...  \n",
       "17  लोकसभा की कार्यावधि 5 वर्ष है पर्ंतु इसे समय स...  \n",
       "19  बढ़ती हुई मौतों displacements और आर्थिक नुकसान...  \n",
       "22  इस्लाम धर्म (الإسلام) ईसाई धर्म के बाद अनुयाइ...  \n",
       "33                                                मेन  \n",
       "34  फारसी रहस्यवाद में मुगल कालीन इस्लामी पाठ्य मे...  \n",
       "40  मगर उनके निधन के पश्चात उनके भाई सरदार वल्लभ भ...  \n",
       "48  -झूला यह हत्थाकुर्सी से मिलती जुलती पोजीशन है ...  \n",
       "50                          श्रेणी:सूचना प्रौद्योगिकी  \n",
       "57  आर्य देवताओं की कोई मूर्ति या मन्दिर नहीं बनात...  \n",
       "58  यह एक छोटी तीन गुम्बद वाली तराशे हुए श्वेत संग...  \n",
       "59                 महात्मा गांधी के साथ सरोजिनी नायडू  \n",
       "61                                      बाहरी कड़ियाँ  \n",
       "69                              बुद्ध और नाचघर (1958)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.262905Z",
     "iopub.status.busy": "2021-11-19T09:41:42.262655Z",
     "iopub.status.idle": "2021-11-19T09:41:42.284823Z",
     "shell.execute_reply": "2021-11-19T09:41:42.284105Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.262873Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    2\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.286876Z",
     "iopub.status.busy": "2021-11-19T09:41:42.286330Z",
     "iopub.status.idle": "2021-11-19T09:41:42.307547Z",
     "shell.execute_reply": "2021-11-19T09:41:42.306561Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.286835Z"
    }
   },
   "outputs": [],
   "source": [
    "lines = lines.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.309820Z",
     "iopub.status.busy": "2021-11-19T09:41:42.309322Z",
     "iopub.status.idle": "2021-11-19T09:41:42.321339Z",
     "shell.execute_reply": "2021-11-19T09:41:42.320675Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.309780Z"
    }
   },
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.322924Z",
     "iopub.status.busy": "2021-11-19T09:41:42.322613Z",
     "iopub.status.idle": "2021-11-19T09:41:42.373245Z",
     "shell.execute_reply": "2021-11-19T09:41:42.372590Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.322888Z"
    }
   },
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.376633Z",
     "iopub.status.busy": "2021-11-19T09:41:42.376442Z",
     "iopub.status.idle": "2021-11-19T09:41:42.387178Z",
     "shell.execute_reply": "2021-11-19T09:41:42.386259Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.376610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.390367Z",
     "iopub.status.busy": "2021-11-19T09:41:42.390118Z",
     "iopub.status.idle": "2021-11-19T09:41:42.429866Z",
     "shell.execute_reply": "2021-11-19T09:41:42.429261Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.390340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.431213Z",
     "iopub.status.busy": "2021-11-19T09:41:42.430897Z",
     "iopub.status.idle": "2021-11-19T09:41:42.506766Z",
     "shell.execute_reply": "2021-11-19T09:41:42.505997Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.431170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:42.508382Z",
     "iopub.status.busy": "2021-11-19T09:41:42.508107Z",
     "iopub.status.idle": "2021-11-19T09:41:43.157662Z",
     "shell.execute_reply": "2021-11-19T09:41:43.156850Z",
     "shell.execute_reply.started": "2021-11-19T09:41:42.508348Z"
    }
   },
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:43.161051Z",
     "iopub.status.busy": "2021-11-19T09:41:43.160846Z",
     "iopub.status.idle": "2021-11-19T09:41:43.896082Z",
     "shell.execute_reply": "2021-11-19T09:41:43.895301Z",
     "shell.execute_reply.started": "2021-11-19T09:41:43.161026Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:43.898716Z",
     "iopub.status.busy": "2021-11-19T09:41:43.898299Z",
     "iopub.status.idle": "2021-11-19T09:41:43.918525Z",
     "shell.execute_reply": "2021-11-19T09:41:43.917865Z",
     "shell.execute_reply.started": "2021-11-19T09:41:43.898669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:43.920369Z",
     "iopub.status.busy": "2021-11-19T09:41:43.919906Z",
     "iopub.status.idle": "2021-11-19T09:41:43.929730Z",
     "shell.execute_reply": "2021-11-19T09:41:43.928968Z",
     "shell.execute_reply.started": "2021-11-19T09:41:43.920332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43137</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>occurring in the environment recently increase...</td>\n",
       "      <td>START_ वातावरण में कार्बन डाइऑक्साइड में हाल ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107772</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>her father aghoranath chattopadhyay was a well...</td>\n",
       "      <td>START_ इनके पिता अघोरनाथ चट्टोपाध्याय एक नामी ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120507</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>nishadraj guh served those three very well in ...</td>\n",
       "      <td>START_ ऋंगवेरपुर में निषादराज गुह ने तीनों की ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28755</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the ordinance that was rejected by loksabha ca...</td>\n",
       "      <td>START_ लोकसभा एक अध्यादेश को अस्वीकृत करने वाल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86303</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>number of</td>\n",
       "      <td>START_ अठारह की संख्या _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "43137   indic2012  occurring in the environment recently increase...   \n",
       "107772  indic2012  her father aghoranath chattopadhyay was a well...   \n",
       "120507  indic2012  nishadraj guh served those three very well in ...   \n",
       "28755   indic2012  the ordinance that was rejected by loksabha ca...   \n",
       "86303   indic2012                                          number of   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "43137   START_ वातावरण में कार्बन डाइऑक्साइड में हाल ह...  \n",
       "107772  START_ इनके पिता अघोरनाथ चट्टोपाध्याय एक नामी ...  \n",
       "120507  START_ ऋंगवेरपुर में निषादराज गुह ने तीनों की ...  \n",
       "28755   START_ लोकसभा एक अध्यादेश को अस्वीकृत करने वाल...  \n",
       "86303                         START_ अठारह की संख्या _END  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:43.931409Z",
     "iopub.status.busy": "2021-11-19T09:41:43.931134Z",
     "iopub.status.idle": "2021-11-19T09:41:44.164699Z",
     "shell.execute_reply": "2021-11-19T09:41:44.163996Z",
     "shell.execute_reply.started": "2021-11-19T09:41:43.931374Z"
    }
   },
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.165992Z",
     "iopub.status.busy": "2021-11-19T09:41:44.165758Z",
     "iopub.status.idle": "2021-11-19T09:41:44.176109Z",
     "shell.execute_reply": "2021-11-19T09:41:44.175238Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.165960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30447"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.178519Z",
     "iopub.status.busy": "2021-11-19T09:41:44.177598Z",
     "iopub.status.idle": "2021-11-19T09:41:44.183926Z",
     "shell.execute_reply": "2021-11-19T09:41:44.183204Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.178423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20506"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.185894Z",
     "iopub.status.busy": "2021-11-19T09:41:44.185429Z",
     "iopub.status.idle": "2021-11-19T09:41:44.280388Z",
     "shell.execute_reply": "2021-11-19T09:41:44.279724Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.185859Z"
    }
   },
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.281800Z",
     "iopub.status.busy": "2021-11-19T09:41:44.281476Z",
     "iopub.status.idle": "2021-11-19T09:41:44.293791Z",
     "shell.execute_reply": "2021-11-19T09:41:44.292800Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.281763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43137</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>occurring in the environment recently increase...</td>\n",
       "      <td>START_ वातावरण में कार्बन डाइऑक्साइड में हाल ह...</td>\n",
       "      <td>67</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107772</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>her father aghoranath chattopadhyay was a well...</td>\n",
       "      <td>START_ इनके पिता अघोरनाथ चट्टोपाध्याय एक नामी ...</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120507</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>nishadraj guh served those three very well in ...</td>\n",
       "      <td>START_ ऋंगवेरपुर में निषादराज गुह ने तीनों की ...</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28755</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>the ordinance that was rejected by loksabha ca...</td>\n",
       "      <td>START_ लोकसभा एक अध्यादेश को अस्वीकृत करने वाल...</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86303</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>number of</td>\n",
       "      <td>START_ अठारह की संख्या _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "43137   indic2012  occurring in the environment recently increase...   \n",
       "107772  indic2012  her father aghoranath chattopadhyay was a well...   \n",
       "120507  indic2012  nishadraj guh served those three very well in ...   \n",
       "28755   indic2012  the ordinance that was rejected by loksabha ca...   \n",
       "86303   indic2012                                          number of   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "43137   START_ वातावरण में कार्बन डाइऑक्साइड में हाल ह...   \n",
       "107772  START_ इनके पिता अघोरनाथ चट्टोपाध्याय एक नामी ...   \n",
       "120507  START_ ऋंगवेरपुर में निषादराज गुह ने तीनों की ...   \n",
       "28755   START_ लोकसभा एक अध्यादेश को अस्वीकृत करने वाल...   \n",
       "86303                         START_ अठारह की संख्या _END   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "43137                    67                   81  \n",
       "107772                   17                   19  \n",
       "120507                    9                   12  \n",
       "28755                    15                   21  \n",
       "86303                     2                    5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.295389Z",
     "iopub.status.busy": "2021-11-19T09:41:44.295070Z",
     "iopub.status.idle": "2021-11-19T09:41:44.304413Z",
     "shell.execute_reply": "2021-11-19T09:41:44.303639Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.295353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2030, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.306140Z",
     "iopub.status.busy": "2021-11-19T09:41:44.305800Z",
     "iopub.status.idle": "2021-11-19T09:41:44.314989Z",
     "shell.execute_reply": "2021-11-19T09:41:44.314234Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.306105Z"
    }
   },
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.316487Z",
     "iopub.status.busy": "2021-11-19T09:41:44.316214Z",
     "iopub.status.idle": "2021-11-19T09:41:44.324068Z",
     "shell.execute_reply": "2021-11-19T09:41:44.323205Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.316454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16970, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.325751Z",
     "iopub.status.busy": "2021-11-19T09:41:44.325415Z",
     "iopub.status.idle": "2021-11-19T09:41:44.338527Z",
     "shell.execute_reply": "2021-11-19T09:41:44.337878Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.325715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.339938Z",
     "iopub.status.busy": "2021-11-19T09:41:44.339635Z",
     "iopub.status.idle": "2021-11-19T09:41:44.348381Z",
     "shell.execute_reply": "2021-11-19T09:41:44.347626Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.339903Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.350271Z",
     "iopub.status.busy": "2021-11-19T09:41:44.349722Z",
     "iopub.status.idle": "2021-11-19T09:41:44.386849Z",
     "shell.execute_reply": "2021-11-19T09:41:44.386193Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.350236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30447, 20506)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.393434Z",
     "iopub.status.busy": "2021-11-19T09:41:44.393231Z",
     "iopub.status.idle": "2021-11-19T09:41:44.397887Z",
     "shell.execute_reply": "2021-11-19T09:41:44.397134Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.393411Z"
    }
   },
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.399493Z",
     "iopub.status.busy": "2021-11-19T09:41:44.399083Z",
     "iopub.status.idle": "2021-11-19T09:41:44.426081Z",
     "shell.execute_reply": "2021-11-19T09:41:44.425427Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.399458Z"
    }
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.427963Z",
     "iopub.status.busy": "2021-11-19T09:41:44.427292Z",
     "iopub.status.idle": "2021-11-19T09:41:44.443985Z",
     "shell.execute_reply": "2021-11-19T09:41:44.443160Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.427924Z"
    }
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.446956Z",
     "iopub.status.busy": "2021-11-19T09:41:44.446750Z",
     "iopub.status.idle": "2021-11-19T09:41:44.462876Z",
     "shell.execute_reply": "2021-11-19T09:41:44.462205Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.446933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93769</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>first staeg th march</td>\n",
       "      <td>START_ पहला चरण मार्च _END</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11072</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>mp mlas disqualification except for defection ...</td>\n",
       "      <td>START_ सांसदविधायक की अयोग्यतादल बदल को छोडकरप...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56909</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>rest of the power lies with jammu kashmir stat...</td>\n",
       "      <td>START_ अवशेष शक्ति जम्मू कश्मीर विधान सभा के प...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111651</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>however he was not against any particular publ...</td>\n",
       "      <td>START_ लेकिन वे किसी विशेष पत्रिका के खिलाफ़ न...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106508</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>nepal news</td>\n",
       "      <td>START_ नेपाल की खबर _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27889</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>post of surtext of postson wiki source</td>\n",
       "      <td>START_ सूर के पद पदों का मूल पाठ विकिस्रोत पर ...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112534</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>this method is adopted for the purpose of some...</td>\n",
       "      <td>START_ इन्हें ऑनलाइन उपयोग कर सकते हैं या डाउन...</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26227</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>category environment</td>\n",
       "      <td>START_ श्रेणीपर्यावरण _END</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123250</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>rites era of hindi literature is known from ye...</td>\n",
       "      <td>START_ हिंदी साहित्य का रीति काल संवत से तक मा...</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113173</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>according to muslims god is one without a seco...</td>\n",
       "      <td>START_ मुसलमानों के अनुसार इश्वर अद्वितीय हैः ...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source                                   english_sentence  \\\n",
       "93769   indic2012                               first staeg th march   \n",
       "11072   indic2012  mp mlas disqualification except for defection ...   \n",
       "56909   indic2012  rest of the power lies with jammu kashmir stat...   \n",
       "111651  indic2012  however he was not against any particular publ...   \n",
       "106508  indic2012                                         nepal news   \n",
       "27889   indic2012             post of surtext of postson wiki source   \n",
       "112534  indic2012  this method is adopted for the purpose of some...   \n",
       "26227   indic2012                               category environment   \n",
       "123250  indic2012  rites era of hindi literature is known from ye...   \n",
       "113173  indic2012  according to muslims god is one without a seco...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "93769                          START_ पहला चरण मार्च _END   \n",
       "11072   START_ सांसदविधायक की अयोग्यतादल बदल को छोडकरप...   \n",
       "56909   START_ अवशेष शक्ति जम्मू कश्मीर विधान सभा के प...   \n",
       "111651  START_ लेकिन वे किसी विशेष पत्रिका के खिलाफ़ न...   \n",
       "106508                           START_ नेपाल की खबर _END   \n",
       "27889   START_ सूर के पद पदों का मूल पाठ विकिस्रोत पर ...   \n",
       "112534  START_ इन्हें ऑनलाइन उपयोग कर सकते हैं या डाउन...   \n",
       "26227                          START_ श्रेणीपर्यावरण _END   \n",
       "123250  START_ हिंदी साहित्य का रीति काल संवत से तक मा...   \n",
       "113173  START_ मुसलमानों के अनुसार इश्वर अद्वितीय हैः ...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "93769                     4                    5  \n",
       "11072                    11                   12  \n",
       "56909                    10                   12  \n",
       "111651                    8                   11  \n",
       "106508                    2                    5  \n",
       "27889                     7                   11  \n",
       "112534                   11                   17  \n",
       "26227                     2                    3  \n",
       "123250                   14                   18  \n",
       "113173                   14                   13  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.464597Z",
     "iopub.status.busy": "2021-11-19T09:41:44.463973Z",
     "iopub.status.idle": "2021-11-19T09:41:44.475827Z",
     "shell.execute_reply": "2021-11-19T09:41:44.474854Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.464561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13576,), (3394,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.478356Z",
     "iopub.status.busy": "2021-11-19T09:41:44.476704Z",
     "iopub.status.idle": "2021-11-19T09:41:44.489132Z",
     "shell.execute_reply": "2021-11-19T09:41:44.488440Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.478319Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.490883Z",
     "iopub.status.busy": "2021-11-19T09:41:44.490438Z",
     "iopub.status.idle": "2021-11-19T09:41:44.500207Z",
     "shell.execute_reply": "2021-11-19T09:41:44.499491Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.490849Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.502102Z",
     "iopub.status.busy": "2021-11-19T09:41:44.501600Z",
     "iopub.status.idle": "2021-11-19T09:41:44.510864Z",
     "shell.execute_reply": "2021-11-19T09:41:44.509996Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.502067Z"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:44.512924Z",
     "iopub.status.busy": "2021-11-19T09:41:44.512352Z",
     "iopub.status.idle": "2021-11-19T09:41:47.697578Z",
     "shell.execute_reply": "2021-11-19T09:41:47.696832Z",
     "shell.execute_reply.started": "2021-11-19T09:41:44.512872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:47.699080Z",
     "iopub.status.busy": "2021-11-19T09:41:47.698842Z",
     "iopub.status.idle": "2021-11-19T09:41:48.433061Z",
     "shell.execute_reply": "2021-11-19T09:41:48.432268Z",
     "shell.execute_reply.started": "2021-11-19T09:41:47.699047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:48.434716Z",
     "iopub.status.busy": "2021-11-19T09:41:48.434432Z",
     "iopub.status.idle": "2021-11-19T09:41:48.447806Z",
     "shell.execute_reply": "2021-11-19T09:41:48.447050Z",
     "shell.execute_reply.started": "2021-11-19T09:41:48.434683Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:41:48.449460Z",
     "iopub.status.busy": "2021-11-19T09:41:48.449165Z",
     "iopub.status.idle": "2021-11-19T09:41:48.461212Z",
     "shell.execute_reply": "2021-11-19T09:41:48.460562Z",
     "shell.execute_reply.started": "2021-11-19T09:41:48.449424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    9134100     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    6152100     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 20507)  6172607     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 22,901,207\n",
      "Trainable params: 22,901,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:56:30.366800Z",
     "iopub.status.busy": "2021-11-19T09:56:30.366432Z",
     "iopub.status.idle": "2021-11-19T09:56:30.372183Z",
     "shell.execute_reply": "2021-11-19T09:56:30.371150Z",
     "shell.execute_reply.started": "2021-11-19T09:56:30.366757Z"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T09:56:31.429623Z",
     "iopub.status.busy": "2021-11-19T09:56:31.428900Z",
     "iopub.status.idle": "2021-11-19T10:18:11.919358Z",
     "shell.execute_reply": "2021-11-19T10:18:11.918663Z",
     "shell.execute_reply.started": "2021-11-19T09:56:31.429574Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Digvijay\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 169s 2s/step - loss: 3.5101 - val_loss: 3.3139\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 174s 2s/step - loss: 3.1501 - val_loss: 3.2010\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 164s 2s/step - loss: 3.0009 - val_loss: 3.0865\n",
      "Epoch 4/50\n",
      " 56/106 [==============>...............] - ETA: 1:14 - loss: 2.8402"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:18:29.999697Z",
     "iopub.status.busy": "2021-11-19T10:18:29.999360Z",
     "iopub.status.idle": "2021-11-19T10:18:30.275056Z",
     "shell.execute_reply": "2021-11-19T10:18:30.273902Z",
     "shell.execute_reply.started": "2021-11-19T10:18:29.999660Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:18:54.107729Z",
     "iopub.status.busy": "2021-11-19T10:18:54.107474Z",
     "iopub.status.idle": "2021-11-19T10:18:54.783912Z",
     "shell.execute_reply": "2021-11-19T10:18:54.783231Z",
     "shell.execute_reply.started": "2021-11-19T10:18:54.107701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:19:19.412649Z",
     "iopub.status.busy": "2021-11-19T10:19:19.411759Z",
     "iopub.status.idle": "2021-11-19T10:19:19.421062Z",
     "shell.execute_reply": "2021-11-19T10:19:19.420273Z",
     "shell.execute_reply.started": "2021-11-19T10:19:19.412600Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:19:24.134441Z",
     "iopub.status.busy": "2021-11-19T10:19:24.134033Z",
     "iopub.status.idle": "2021-11-19T10:19:24.138311Z",
     "shell.execute_reply": "2021-11-19T10:19:24.137603Z",
     "shell.execute_reply.started": "2021-11-19T10:19:24.134404Z"
    }
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:19:27.629995Z",
     "iopub.status.busy": "2021-11-19T10:19:27.629167Z",
     "iopub.status.idle": "2021-11-19T10:19:29.916729Z",
     "shell.execute_reply": "2021-11-19T10:19:29.915072Z",
     "shell.execute_reply.started": "2021-11-19T10:19:27.629955Z"
    }
   },
   "outputs": [],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T10:19:33.282067Z",
     "iopub.status.busy": "2021-11-19T10:19:33.281814Z",
     "iopub.status.idle": "2021-11-19T10:19:33.734660Z",
     "shell.execute_reply": "2021-11-19T10:19:33.733923Z",
     "shell.execute_reply.started": "2021-11-19T10:19:33.282038Z"
    }
   },
   "outputs": [],
   "source": [
    "a = y_train[k:k+1].values[0][6:-4]\n",
    "b = decoded_sentence[:-4]\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "score = sentence_bleu( a, b)\n",
    "print('Bleu score:', '%3f'%score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
